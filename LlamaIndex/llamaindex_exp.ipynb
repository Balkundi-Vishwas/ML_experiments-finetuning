{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain_openai import AzureOpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = AzureChatOpenAI(\n",
    "            azure_deployment=\"gpt-35-turbo\",\n",
    "            api_version=\"2023-06-01-preview\",  \n",
    "            temperature=0,\n",
    "            max_tokens=None,\n",
    "            timeout=None,\n",
    "            max_retries=2,\n",
    "            azure_endpoint=\"https://oai-tss-sweden.openai.azure.com/\",\n",
    "            api_key=\"f0c2aee69c914b35aa55732deb3532be\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import Document,SimpleDirectoryReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = SimpleDirectoryReader(\n",
    "    input_files = [r\"C:\\Projects\\ml_experiments\\LlamaIndex\\dataset1.pdf\"]\n",
    ").load_data()\n",
    "\n",
    "documents = Document(text = \"\\n\\n\".join([doc.text for doc in documents]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "for doc in documents:\n",
    "    print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from llama_index.core.node_parser import SentenceWindowNodeParser\n",
    "from llama_index.core import VectorStoreIndex, ServiceContext, load_index_from_storage, StorageContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'llama_index' has no attribute 'settings'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain_openai\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AzureOpenAIEmbeddings\n\u001b[1;32m----> 2\u001b[0m \u001b[43mllama_index\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msettings\u001b[49m\u001b[38;5;241m.\u001b[39membed_model \u001b[38;5;241m=\u001b[39m AzureOpenAIEmbeddings(\n\u001b[0;32m      3\u001b[0m                 azure_deployment\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtss-ada_embedding\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      4\u001b[0m                 openai_api_version\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2023-05-15\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      5\u001b[0m                 azure_endpoint\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://oai-tss-sweden.openai.azure.com/\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      6\u001b[0m                 api_key\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mf0c2aee69c914b35aa55732deb3532be\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      7\u001b[0m             )\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'llama_index' has no attribute 'settings'"
     ]
    }
   ],
   "source": [
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "llama_index.settings.embed_model = AzureOpenAIEmbeddings(\n",
    "                azure_deployment=\"tss-ada_embedding\",\n",
    "                openai_api_version=\"2023-05-15\",\n",
    "                azure_endpoint=\"https://oai-tss-sweden.openai.azure.com/\",\n",
    "                api_key=\"f0c2aee69c914b35aa55732deb3532be\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_build_index(documents,llm,embed_model=\"local:BAAI/bge-small-en-v1.5\",sentence_window_size=3,save_dir=\"./vector_store/index\"):\n",
    "  \n",
    "  node_parser = SentenceWindowNodeParser(\n",
    "      window_size = sentence_window_size,\n",
    "      window_metadata_key = \"window\",\n",
    "      original_text_metadata_key = \"original_text\"\n",
    "  )\n",
    "\n",
    "#   sentence_context = ServiceContext.from_defaults(\n",
    "#       llm = llm,\n",
    "#       embed_model= embeddings,\n",
    "#       node_parser = node_parser,\n",
    "#   )\n",
    "\n",
    "  if not os.path.exists(save_dir):\n",
    "        # create and load the index\n",
    "        index = VectorStoreIndex.from_documents(\n",
    "            [documents], service_context=sentence_context\n",
    "        )\n",
    "        index.storage_context.persist(persist_dir=save_dir)\n",
    "  else:\n",
    "      # load the existing index\n",
    "      index = load_index_from_storage(\n",
    "          StorageContext.from_defaults(persist_dir=save_dir),\n",
    "          service_context=sentence_context,\n",
    "      )\n",
    "\n",
    "  return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "ServiceContext is deprecated. Use llama_index.settings.Settings instead, or pass in modules to local functions/methods/interfaces.\nSee the docs for updated usage/migration: \nhttps://docs.llamaindex.ai/en/stable/module_guides/supporting_modules/service_context_migration/",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m vector_index \u001b[38;5;241m=\u001b[39m \u001b[43mget_build_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocuments\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdocuments\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mllm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mllm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membed_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlocal:BAAI/bge-small-en-v1.5\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msentence_window_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./vector_store/index\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[22], line 9\u001b[0m, in \u001b[0;36mget_build_index\u001b[1;34m(documents, llm, embed_model, sentence_window_size, save_dir)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_build_index\u001b[39m(documents,llm,embed_model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlocal:BAAI/bge-small-en-v1.5\u001b[39m\u001b[38;5;124m\"\u001b[39m,sentence_window_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,save_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./vector_store/index\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m      3\u001b[0m   node_parser \u001b[38;5;241m=\u001b[39m SentenceWindowNodeParser(\n\u001b[0;32m      4\u001b[0m       window_size \u001b[38;5;241m=\u001b[39m sentence_window_size,\n\u001b[0;32m      5\u001b[0m       window_metadata_key \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwindow\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      6\u001b[0m       original_text_metadata_key \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moriginal_text\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      7\u001b[0m   )\n\u001b[1;32m----> 9\u001b[0m   sentence_context \u001b[38;5;241m=\u001b[39m \u001b[43mServiceContext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_defaults\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m      \u001b[49m\u001b[43mllm\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mllm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m      \u001b[49m\u001b[43membed_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnode_parser\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnode_parser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(save_dir):\n\u001b[0;32m     16\u001b[0m         \u001b[38;5;66;03m# create and load the index\u001b[39;00m\n\u001b[0;32m     17\u001b[0m         index \u001b[38;5;241m=\u001b[39m VectorStoreIndex\u001b[38;5;241m.\u001b[39mfrom_documents(\n\u001b[0;32m     18\u001b[0m             [documents], service_context\u001b[38;5;241m=\u001b[39msentence_context\n\u001b[0;32m     19\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\vishwas.balkundi\\miniforge3\\envs\\env_ml\\Lib\\site-packages\\llama_index\\core\\service_context.py:31\u001b[0m, in \u001b[0;36mServiceContext.from_defaults\u001b[1;34m(cls, **kwargs)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfrom_defaults\u001b[39m(\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m     24\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mServiceContext\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m     25\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Create a ServiceContext from defaults.\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \n\u001b[0;32m     27\u001b[0m \u001b[38;5;124;03m    NOTE: Deprecated, use llama_index.settings.Settings instead or pass in\u001b[39;00m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;124;03m    modules to local functions/methods/interfaces.\u001b[39;00m\n\u001b[0;32m     29\u001b[0m \n\u001b[0;32m     30\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 31\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     32\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mServiceContext is deprecated. Use llama_index.settings.Settings instead, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     33\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mor pass in modules to local functions/methods/interfaces.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     34\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSee the docs for updated usage/migration: \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     35\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://docs.llamaindex.ai/en/stable/module_guides/supporting_modules/service_context_migration/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     36\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: ServiceContext is deprecated. Use llama_index.settings.Settings instead, or pass in modules to local functions/methods/interfaces.\nSee the docs for updated usage/migration: \nhttps://docs.llamaindex.ai/en/stable/module_guides/supporting_modules/service_context_migration/"
     ]
    }
   ],
   "source": [
    "vector_index = get_build_index(documents=documents, llm=llm, embed_model=\"local:BAAI/bge-small-en-v1.5\", sentence_window_size=3, save_dir=\"./vector_store/index\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Invalid switch - \"vector_store\".\n"
     ]
    }
   ],
   "source": [
    "ls -lh ./vector_store/index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
